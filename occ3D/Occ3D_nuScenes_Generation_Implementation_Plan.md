# Occ3D-nuScenes æ•°æ®é›†ç”Ÿæˆå®Œæ•´å®æ–½æ–¹æ¡ˆ

**æ–‡æ¡£ç‰ˆæœ¬**: v1.1  
**åˆ›å»ºæ—¥æœŸ**: 2025-01-27  
**æœ€åæ›´æ–°**: 2025-01-27  
**é¡¹ç›®è·¯å¾„**: `E:\Chery\dz\Occ\Occ3D-master`  
**çŠ¶æ€**: å·²å®ç°æ ¸å¿ƒåŠŸèƒ½ï¼Œæ”¯æŒå•è¿›ç¨‹å’Œå¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†

---

## ç›®å½•

1. [é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡](#1-é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡)
2. [æ•°æ®æµæ€»è§ˆ](#2-æ•°æ®æµæ€»è§ˆ)
3. [æŠ€æœ¯æ–¹æ¡ˆè¯¦ç»†è®¾è®¡](#3-æŠ€æœ¯æ–¹æ¡ˆè¯¦ç»†è®¾è®¡)
4. [CUDA Algorithm 3 å®ç°ç»†èŠ‚](#4-cuda-algorithm-3-å®ç°ç»†èŠ‚)
5. [æ–‡ä»¶ç»“æ„ä¸è¾“å‡ºæ ¼å¼](#5-æ–‡ä»¶ç»“æ„ä¸è¾“å‡ºæ ¼å¼)
6. [é…ç½®å‚æ•°ä¸å‘½ä»¤è¡Œæ¥å£](#6-é…ç½®å‚æ•°ä¸å‘½ä»¤è¡Œæ¥å£)
7. [éªŒè¯ä¸æ£€æŸ¥ç‚¹](#7-éªŒè¯ä¸æ£€æŸ¥ç‚¹)
8. [ä¾èµ–ä¸ç¯å¢ƒè¦æ±‚](#8-ä¾èµ–ä¸ç¯å¢ƒè¦æ±‚)

---

## 1. é¡¹ç›®èƒŒæ™¯ä¸ç›®æ ‡

### 1.1 é¡¹ç›®ç›®æ ‡

æ ¹æ®è®ºæ–‡ [Occ3D: A Large-Scale 3D Occupancy Prediction Benchmark for Autonomous Driving](https://arxiv.org/pdf/2304.14365) å’Œå®˜æ–¹ä»“åº“ [Tsinghua-MARS-Lab/Occ3D](https://github.com/Tsinghua-MARS-Lab/Occ3D)ï¼Œå®ç° **Occ3D-nuScenes** åŸºå‡†æ•°æ®é›†çš„å®Œæ•´ç”Ÿæˆæµç¨‹ã€‚

**æ ¸å¿ƒè¦æ±‚**ï¼š
- ç”Ÿæˆçš„æ•°æ®é›†ç›®å½•ç»“æ„å¿…é¡»ä¸å®˜æ–¹ README å®Œå…¨ä¸€è‡´
- å®ç°è®ºæ–‡ä¸­æè¿°çš„**ä¸‰é˜¶æ®µæ ‡ç­¾ç”Ÿæˆæµæ°´çº¿**ï¼ˆVoxel Densification â†’ Occlusion Reasoning â†’ Image-guided Refinementï¼‰
- æ”¯æŒå¤š GPU å¹¶è¡Œå¤„ç†ï¼ˆ2~4 å¼  GPUï¼‰
- æœåŠ¡å™¨ä¸Šå­˜æ”¾å®Œæ•´ nuScenes v1.0-trainval æ•°æ®ï¼Œæœ¬åœ°ä»…å»ºç«‹ç›®å½•æ¶æ„

### 1.2 è¾“å…¥æ•°æ®æº

- **nuScenes v1.0-trainval** å®Œæ•´æ•°æ®ï¼ˆæœåŠ¡å™¨ç«¯ï¼‰
- åŒ…å«ï¼š
  - LiDAR ç‚¹äº‘ï¼ˆ`samples/LIDAR_TOP/` å’Œ `sweeps/LIDAR_TOP/`ï¼‰
  - 6 ä¸ªç›¸æœºå›¾åƒï¼ˆ`samples/CAM_*/`ï¼‰
  - LiDAR è¯­ä¹‰åˆ†å‰²æ ‡ç­¾ï¼ˆ`lidarseg/v1.0-trainval/`ï¼‰
  - å…ƒæ•°æ® JSONï¼ˆ`v1.0-trainval/*.json`ï¼‰

### 1.3 è¾“å‡ºæ•°æ®é›†è§„æ ¼

æ ¹æ® [Occ3D å®˜æ–¹ README](https://github.com/Tsinghua-MARS-Lab/Occ3D)ï¼š

| å±æ€§ | æ•°å€¼ |
|------|------|
| è®­ç»ƒ/éªŒè¯/æµ‹è¯• | 600 / 150 / 250 scenes |
| ç›¸æœºæ•°é‡ | 6 |
| ä½“ç´ å°ºå¯¸ | [0.4m, 0.4m, 0.4m] |
| ç©ºé—´èŒƒå›´ | [-40m, -40m, -1m, 40m, 40m, 5.4m] |
| ç½‘æ ¼å¤§å° | [200, 200, 16] |
| ç±»åˆ«æ•° | 18 (0-16: nuScenes-lidarseg, 17: free) |

**è¾“å‡ºç›®å½•ç»“æ„**ï¼ˆå¿…é¡»ä¸¥æ ¼å¯¹é½å®˜æ–¹ï¼‰ï¼š
```
Occpancy3D-nuScenes-V1.0/
â”œâ”€â”€ trainval/
â”‚   â”œâ”€â”€ imgs/
â”‚   â”‚   â”œâ”€â”€ CAM_BACK/
â”‚   â”‚   â”œâ”€â”€ CAM_BACK_LEFT/
â”‚   â”‚   â”œâ”€â”€ CAM_BACK_RIGHT/
â”‚   â”‚   â”œâ”€â”€ CAM_FRONT/
â”‚   â”‚   â”œâ”€â”€ CAM_FRONT_LEFT/
â”‚   â”‚   â””â”€â”€ CAM_FRONT_RIGHT/
â”‚   â”œâ”€â”€ gts/
â”‚   â”‚   â”œâ”€â”€ [scene_name]/
â”‚   â”‚   â”‚   â”œâ”€â”€ [frame_token]/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ labels.npz
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ annotations.json
â””â”€â”€ test/
    â”œâ”€â”€ imgs/
    â””â”€â”€ annotations.json
```

---

## 2. æ•°æ®æµæ€»è§ˆ

### 2.1 å¤„ç†æµç¨‹ï¼ˆæ¯ä¸ª keyframeï¼‰

```
è¾“å…¥: nuScenes keyframe (sample_token)
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: Voxel Densificationï¼ˆä½“ç´ å¯†é›†åŒ–ï¼‰                   â”‚
â”‚ â€¢ Multi-frame Aggregation: èšåˆ 21 ä¸ª keyframeï¼ˆå‰åå„10+å½“å‰ï¼‰â”‚
â”‚ â€¢ (å¯é€‰) Sweeps åŠ å…¥: å¼•å…¥æœªæ ‡æ³¨ sweeps æå‡è¦†ç›–              â”‚
â”‚ â€¢ (å¯é€‰) Label Assignment (KNN): ç»™ sweeps ç‚¹åˆ†é…è¯­ä¹‰æ ‡ç­¾     â”‚
â”‚ â€¢ Dynamic objects alignment: åŠ¨æ€ç‰©ä½“å®ä¾‹å¯¹é½å‡å°‘æ‹–å½±         â”‚
â”‚ â€¢ (å¯é€‰) Mesh Reconstruction: TSDF/mesh è¡¥æ´å¾—åˆ°æ›´è‡´å¯†è¡¨é¢     â”‚
â”‚ è¾“å‡º: densified semantic pointsï¼ˆç¨ å¯†è¯­ä¹‰ç‚¹äº‘ï¼‰               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: Occlusion Reasoningï¼ˆé®æŒ¡æ¨ç†ï¼‰                      â”‚
â”‚ â€¢ LiDAR Visibility (Algorithm 2): ray casting ç”Ÿæˆ free/occ   â”‚
â”‚   - å¾—åˆ° semanticsï¼ˆå« free=17ï¼‰                              â”‚
â”‚   - å¾—åˆ° mask_lidarï¼ˆLiDAR view observed maskï¼‰               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: Camera Visibility (Algorithm 3, CUDA)               â”‚
â”‚ â€¢ å¯¹ 6 ç›¸æœºæ¯åƒç´ å‘å°„å°„çº¿ï¼ˆé»˜è®¤åŸå§‹åˆ†è¾¨ç‡ï¼‰                    â”‚
â”‚ â€¢ 3D DDA éå†ï¼šé‡åˆ°ç¬¬ä¸€ä¸ª occupied voxel ååœæ­¢ï¼ˆé®æŒ¡ç»ˆæ­¢ï¼‰   â”‚
â”‚ â€¢ å¾—åˆ° mask_camera_raysï¼ˆcamera rays observed maskï¼‰          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 3: Image-guided Voxel Refinementï¼ˆå›¾åƒå¼•å¯¼ä½“ç´ ç»†åŒ–ï¼‰    â”‚
â”‚ â€¢ ä½¿ç”¨ 2D è¯­ä¹‰ï¼ˆæ¥è‡ª 2D åˆ†å‰²æ¨¡å‹æˆ–æ ‡æ³¨ï¼‰ä¿®å‰ª 3D è¾¹ç•Œ           â”‚
â”‚ â€¢ æ²¿åƒç´ å°„çº¿ï¼šé‡åˆ°é¦–ä¸ªè¯­ä¹‰ä¸€è‡´ voxel å‰çš„ voxels ç½®ä¸º free      â”‚
â”‚ â€¢ (å»ºè®®) ç»†åŒ–åé‡ç®—ä¸€æ¬¡ mask_camera_rays ä¿æŒä¸€è‡´æ€§            â”‚
â”‚ è¾“å‡º: refined semantics                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Export: å†™ç›˜ä¸å…ƒä¿¡æ¯                                          â”‚
â”‚ â€¢ mask_camera = mask_lidar AND mask_camera_rays               â”‚
â”‚ â€¢ å†™å…¥ labels.npzï¼ˆXYZï¼‰ä¸ annotations.json                   â”‚
â”‚ â€¢ imgs/ ç”¨ symlink/hardlink/copy å¯¹é½å®˜æ–¹ç›®å½•ç»“æ„              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
è¾“å‡º: å®Œæ•´çš„Occ3D-nuScenesæ ¼å¼æ•°æ®
```

### 2.2 å…³é”®è®¾è®¡å†³ç­–

1. **å¤šå¸§èšåˆçª—å£**ï¼šnuScenes ä½¿ç”¨ **21 ä¸ª keyframe**ï¼ˆå½“å‰å¸§ + å‰åå„ 10 ä¸ªï¼‰
2. **(å¯é€‰) Label Assignment (KNN)**ï¼šå½“å¼•å…¥æ— æ ‡ç­¾ sweeps æ—¶ï¼Œé€šè¿‡ KNN ä» keyframe ä¼ æ’­è¯­ä¹‰æ ‡ç­¾
3. **(å¯é€‰) Mesh Reconstruction**ï¼šTSDF/mesh è¡¥æ´å¾—åˆ°æ›´è‡´å¯†è¡¨é¢ï¼ˆæ›´æ¥è¿‘è®ºæ–‡ Stage 1ï¼‰
4. **åŠ¨æ€ç‰©ä½“å¤„ç†**ï¼šåªå¯¹ vehicle/pedestrian/bicycle/motorcycle åš instance å¯¹é½ï¼Œmovable_objectï¼ˆbarrier/traffic_coneï¼‰æŒ‰é™æ€å¤„ç†
5. **LiDAR Visibility Mask**ï¼š`mask_lidar` ç”± LiDAR ray casting å¾—åˆ°ï¼ˆStage 2 æ ¸å¿ƒäº§ç‰©ä¹‹ä¸€ï¼‰
6. **mask_camera å®šä¹‰**ï¼š`mask_camera = mask_lidar AND mask_camera_rays`ï¼ˆç¡®ä¿åªåœ¨ LiDAR observed åŒºåŸŸå†…è¯„æµ‹ï¼‰
7. **ç›¸æœºåˆ†è¾¨ç‡**ï¼šé»˜è®¤ä½¿ç”¨ nuScenes **åŸå§‹åˆ†è¾¨ç‡**ï¼ˆä¸è®ºæ–‡ä¿æŒä¸€è‡´ï¼‰ï¼Œå¯é€‰åˆ‡æ¢åˆ° 928Ã—1600ï¼ˆåŒæ—¶ç¼©æ”¾ Kï¼‰
8. **Stage 3 Image-guided refinement**ï¼šä½¿ç”¨ 2D è¯­ä¹‰ä¿®å‰ª 3D è¾¹ç•Œï¼ˆæ›´æ¥è¿‘è®ºæ–‡ Stage 3ï¼‰
9. **æ•°æ®æ ¼å¼**ï¼šç»Ÿä¸€ä½¿ç”¨ **XYZ é¡ºåº**ï¼Œdtype ä¸º `uint8`

---

## 3. æŠ€æœ¯æ–¹æ¡ˆè¯¦ç»†è®¾è®¡

### 3.1 Stage 1: Voxel Densificationï¼ˆä½“ç´ å¯†é›†åŒ–ï¼‰

#### 3.1.1 è¾“å…¥æ•°æ®è¯»å–

- ä½¿ç”¨ `nuscenes-devkit` è¯»å–ï¼š
  - `sample.json`: keyframe åˆ—è¡¨
  - `sample_data.json`: LiDAR å’Œç›¸æœºæ•°æ®è·¯å¾„
  - `ego_pose.json`: è½¦è¾†ä½å§¿
  - `calibrated_sensor.json`: ä¼ æ„Ÿå™¨æ ‡å®šå‚æ•°
  - `lidarseg.json`: LiDAR è¯­ä¹‰æ ‡ç­¾æ–‡ä»¶è·¯å¾„

- å¯¹æ¯ä¸ª target keyframeï¼Œæ”¶é›†ï¼š
  - å½“å‰å¸§ + å‰åå„ 10 ä¸ª keyframeï¼ˆå…± 21 å¸§ï¼‰
  - æ¯å¸§çš„ LiDAR ç‚¹äº‘ï¼ˆ`.pcd.bin`ï¼‰å’Œ lidarseg æ ‡ç­¾ï¼ˆ`.bin`ï¼‰

#### 3.1.2 åæ ‡å˜æ¢

**ç›®æ ‡**ï¼šå°†æ‰€æœ‰ source keyframe çš„ç‚¹äº‘å˜æ¢åˆ° **target ego åæ ‡ç³»**

**å˜æ¢é“¾**ï¼š
```
p_lidar_s â†’ p_ego_s â†’ p_global â†’ p_ego_t
```

**æ•°å­¦è¡¨ç¤º**ï¼š
$$ p^{\text{ego}_t} = \left( T^{\text{ego}_t}_{\text{global}} \right)^{-1} \cdot T^{\text{global}}_{\text{ego}_s} \cdot T^{\text{ego}_s}_{\text{lidar}_s} \cdot p^{\text{lidar}_s} $$

**å®ç°**ï¼š

- ä½¿ç”¨ `pyquaternion` å¤„ç†å››å…ƒæ•°æ—‹è½¬
- ä½¿ç”¨ `nuscenes-devkit` çš„ `transform_matrix` å·¥å…·å‡½æ•°

#### 3.1.3 åŠ¨æ€ç‰©ä½“å¯¹é½

**åŠ¨æ€ç±»åˆ«åˆ—è¡¨**ï¼ˆæ ¹æ® nuScenes-lidarseg ç±»åˆ«å®šä¹‰ï¼‰ï¼š
- `vehicle.car` (lidarseg index: 4)
- `vehicle.truck` (10)
- `vehicle.bus` (3)
- `vehicle.trailer` (9)
- `vehicle.construction` (5)
- `human.pedestrian.*` (7)
- `vehicle.bicycle` (2)
- `vehicle.motorcycle` (6)

**å¯¹é½ç­–ç•¥**ï¼š
1. å¯¹æ¯ä¸ª source keyframeï¼š
   - è¯»å–è¯¥å¸§çš„ `sample_annotation`ï¼ˆ3D bounding boxesï¼‰
   - ä½¿ç”¨ `utils/points_in_bbox.py:points_in_rbbox` ç­›é€‰ box å†…çš„ç‚¹
2. å¯¹åŠ¨æ€ç±»åˆ«çš„ç‚¹ï¼š
   - æ£€æŸ¥è¯¥ `instance_token` æ˜¯å¦åœ¨ target keyframe ä¹Ÿå­˜åœ¨
   - å¦‚æœå­˜åœ¨ï¼š
     - å°† source box å†…çš„ç‚¹å˜æ¢åˆ° **box-local åæ ‡ç³»**
     - å†ç”¨ target box çš„ pose å˜æ¢å› target ego åæ ‡ç³»
   - å¦‚æœä¸å­˜åœ¨ï¼šä¸¢å¼ƒè¿™äº›ç‚¹ï¼ˆé¿å…å¹½çµæ®‹å½±ï¼‰
3. å¯¹é™æ€ç‚¹ï¼šç›´æ¥ä½¿ç”¨ ego/global å˜æ¢

**å¤ç”¨ç°æœ‰ä»£ç **ï¼š
- `utils/points_in_bbox.py:points_in_rbbox` - æ—‹è½¬ 3D box å†…ç‚¹ç­›é€‰
- `utils/points_in_bbox.py:center_to_corner_box3d` - box è§’ç‚¹è®¡ç®—

#### 3.1.4 è¾“å‡º

- `P_agg`: èšåˆåçš„ç‚¹äº‘åæ ‡ `(N, 3)`ï¼Œåœ¨ target ego åæ ‡ç³»
- `L_agg`: å¯¹åº”çš„ lidarseg è¯­ä¹‰æ ‡ç­¾ `(N,)`ï¼Œå–å€¼ 0~16

#### 3.1.5 (å¯é€‰) Label Assignment (KNN) â€”â€” ç»™ sweeps ç‚¹èµ‹è¯­ä¹‰æ ‡ç­¾

å¯¹ç…§ `cursor_gen_files/Occ3D_Paper_Detailed_Interpretation.md`ï¼šè®ºæ–‡æµæ°´çº¿åœ¨å­˜åœ¨â€œæœªæ ‡æ³¨å¸§/é keyframeâ€çš„æƒ…å†µä¸‹ï¼Œéœ€è¦é€šè¿‡ KNN ç»™è¿™äº›ç‚¹èµ‹è¯­ä¹‰æ ‡ç­¾ï¼ˆWaymo 10Hz vs 2Hz çš„åœºæ™¯æ›´å…¸å‹ï¼‰ã€‚\n
åœ¨ nuScenes ä¸Šï¼Œå¦‚æœæˆ‘ä»¬ä¸ºäº† densification å¼•å…¥ `sweeps/LIDAR_TOP`ï¼ˆé€šå¸¸æ²¡æœ‰ lidarseg æ ‡æ³¨ï¼‰ï¼Œä¹Ÿå¿…é¡»å®ç°è¿™ä¸€æ­¥ã€‚

**è¾“å…¥**ï¼š
- `P_key (N1,3)`: å·²æœ‰è¯­ä¹‰çš„ keyframe ç‚¹äº‘ï¼ˆå·²å¯¹é½åˆ° target egoï¼‰
- `L_key (N1,)`: `P_key` çš„ lidarseg è¯­ä¹‰ï¼ˆ0~16ï¼‰
- `P_sweep (N2,3)`: sweeps ç‚¹äº‘ï¼ˆå·²å¯¹é½åˆ° target egoï¼‰

**è¾“å‡º**ï¼š
- `L_sweep (N2,)`: ç»™æ¯ä¸ª sweep ç‚¹åˆ†é…çš„ä¼ªæ ‡ç­¾ï¼ˆ0~16ï¼‰

**ç®—æ³•å»ºè®®ï¼ˆå·¥ç¨‹å¯è½åœ°ï¼‰**ï¼š
- åœ¨ `P_key` ä¸Šæ„å»º KDTreeï¼ˆ`sklearn.neighbors.KDTree` æˆ– `faiss`ï¼‰
- å¯¹æ¯ä¸ª sweep ç‚¹æ‰¾ `k` ä¸ªæœ€è¿‘é‚» key ç‚¹ï¼Œè¯­ä¹‰å–å¤šæ•°æŠ•ç¥¨ï¼ˆmodeï¼‰
- å…¸å‹è¶…å‚æ•°ï¼š`k=5`ï¼Œå¯åŠ  `max_radius` é˜²æ­¢è¿œè·ç¦»é”™è¯¯ä¼ æ’­

**æ•´åˆ**ï¼š
- `P_dense = concat(P_key, P_sweep)`
- `L_dense = concat(L_key, L_sweep)`

#### 3.1.6 (å¯é€‰) Mesh Reconstruction â€”â€” TSDF/mesh è¡¥æ´å¾—åˆ°æ›´è‡´å¯†è¡¨é¢

å¯¹ç…§ `cursor_gen_files/Occ3D_Paper_Detailed_Interpretation.md`ï¼šè®ºæ–‡åœ¨ Stage 1 ä¸­æåˆ° mesh/TSDF é‡å»ºç”¨äºè¡¥æ´ï¼Œè¿›ä¸€æ­¥æé«˜ recallã€‚\n
è¯¥æ­¥éª¤ç›®æ ‡æ˜¯æŠŠç¨€ç–ç‚¹äº‘è¡¥æˆæ›´è¿ç»­çš„è¡¨é¢ï¼Œå†è¿›è¡Œåç»­ä½“ç´ ä¸å¯è§æ€§æ¨ç†ã€‚

**è¾“å…¥**ï¼š`P_dense, L_dense`\n
**è¾“å‡º**ï¼š`P_mesh_dense, L_mesh_dense`ï¼ˆä» mesh è¡¨é¢é‡‡æ ·å‡ºçš„æ›´è‡´å¯†ç‚¹äº‘ï¼Œä»å¸¦è¯­ä¹‰ï¼‰

**å®ç°è·¯å¾„ï¼ˆå»ºè®®åˆ†ä¸¤æ¡£ï¼‰**ï¼š
- **å®ç°æ¡£ Aï¼ˆæ˜“è½åœ°ï¼‰**ï¼šOpen3D TSDF integration æˆ– Poisson reconstruction â†’ è¡¨é¢é‡‡æ · â†’ è¯­ä¹‰ç»§æ‰¿
- **å®ç°æ¡£ Bï¼ˆæ›´æ¥è¿‘è®ºæ–‡ï¼‰**ï¼šé›†æˆ TSDF/VDBFusion ç­‰å®ç°ï¼›å¯¹åœ°é¢ç±»å•ç‹¬åšæ‹Ÿåˆ/è¡¥ç‚¹ï¼Œé¿å… TSDF çš„ ground artifact

**å¼€å…³å»ºè®®**ï¼š
- `--enable-sweeps-densification`ï¼šæ˜¯å¦å¼•å…¥ sweeps å¹¶å¯¹ sweeps åš KNN è¯­ä¹‰èµ‹å€¼ï¼ˆè¿™ä¸¤ä¸ªé€šå¸¸éœ€è¦ç»‘å®šï¼‰
- `--enable-mesh-recon`ï¼šæ˜¯å¦åš mesh/TSDF è¡¥æ´
- `--mesh-recon-mode {tsdf, poisson}`ï¼šmesh é‡å»ºæ¨¡å¼
  

---

### 3.2 Stage 2: Occlusion Reasoning â€”â€” LiDAR Visibility Maskï¼ˆAlgorithm 2ï¼‰

#### 3.2.1 ä½“ç´ ç½‘æ ¼å‚æ•°ï¼ˆå›ºå®šï¼‰

```python
pc_range = [-40.0, -40.0, -1.0, 40.0, 40.0, 5.4]  # [x_min, y_min, z_min, x_max, y_max, z_max]
voxel_size = [0.4, 0.4, 0.4]  # [vx, vy, vz]
grid_shape = (200, 200, 16)  # (X, Y, Z)
```

#### 3.2.2 è¾“å…¥å‡†å¤‡ï¼ˆAlgorithm 2 Inputsï¼‰

å¯¹ç…§ `cursor_gen_files/Occ3D_Paper_Detailed_Interpretation.md` çš„ Algorithm 2ï¼šè¿™ä¸€æ­¥çš„è¾“å…¥ä¸ä»…æ˜¯ç‚¹äº‘ï¼Œè¿˜éœ€è¦**æ¯æ¡ LiDAR beam çš„èµ·ç‚¹ï¼ˆLiDAR originï¼‰**ä»¥åŠç»Ÿä¸€çš„ä½“ç´ ç½‘æ ¼å®šä¹‰ã€‚

**è¾“å…¥**ï¼š
- `P_dense (N, 3)`: Stage 1 è¾“å‡ºçš„ç¨ å¯†è¯­ä¹‰ç‚¹äº‘ï¼ˆåœ¨ target ego åæ ‡ç³»ï¼‰
- `L_dense (N,)`: `P_dense` çš„è¯­ä¹‰æ ‡ç­¾ï¼ˆ0~16ï¼‰
- `lidar_origins`: èšåˆçª—å£å†…æ¯ä¸ª keyframe çš„ LiDAR originï¼ˆå‡å·²å˜æ¢åˆ° target ego åæ ‡ç³»ï¼‰
- `pc_range, voxel_size, grid_shape`: ä½“ç´ ç½‘æ ¼å®šä¹‰ï¼ˆå›ºå®šä¸º Occ3D-nuScenes è§„æ ¼ï¼‰

**è¾“å‡º**ï¼š
- `semantics[X,Y,Z] uint8`
- `mask_lidar[X,Y,Z] uint8`

#### 3.2.2 Ray Casting ç®—æ³•ï¼ˆAlgorithm 2 æ€æƒ³ï¼‰

**æ ¸å¿ƒç»Ÿè®¡é‡**ï¼š
- `voxel_occ_count[X,Y,Z]`: è¢«ç‚¹"å‘½ä¸­"çš„æ¬¡æ•°
- `voxel_free_count[X,Y,Z]`: è¢«å°„çº¿"ç©¿è¿‡"çš„æ¬¡æ•°

**å¤„ç†æµç¨‹**ï¼ˆå¯¹èšåˆçª—å£å†…æ¯ä¸ª keyframeï¼‰ï¼š
1. è¯»å–è¯¥å¸§çš„ LiDAR originï¼ˆä» `calibrated_sensor` å’Œ `ego_pose` è®¡ç®—ï¼‰
2. å°†è¯¥ origin å˜æ¢åˆ° target ego åæ ‡ç³»
3. å¯¹è¯¥å¸§çš„æ¯ä¸ªç‚¹ï¼ˆå·²åœ¨ target egoï¼‰ï¼š
   - è®¡ç®—ç‚¹æ‰€åœ¨çš„ voxel ç´¢å¼• `target_voxel`
   - `atomicAdd(voxel_occ_count[target_voxel], 1)`
   - ä½¿ç”¨ **3D DDA ç®—æ³•**ï¼ˆAlgorithm 1ï¼‰ä» origin åˆ° `target_voxel` éå†ï¼š
     - å¯¹è·¯å¾„ä¸Šçš„æ¯ä¸ª voxelï¼š`atomicAdd(voxel_free_count[voxel_index], 1)`

**3D DDA å®ç°è¦ç‚¹**ï¼ˆå‚è€ƒè®ºæ–‡è§£è¯»æ–‡æ¡£ï¼‰ï¼š
- ä½¿ç”¨ `EPS = 1e-9` é¿å…è¾¹ç•Œæ¡ä»¶é—®é¢˜
- è®¡ç®— `tDelta`ï¼ˆè·¨è¿‡ä½“ç´ è¾¹é•¿æ‰€éœ€çš„å‚æ•° t å¢é‡ï¼‰
- ä½¿ç”¨ `tMax` åˆ¤æ–­ä¸‹ä¸€æ¬¡è·¨è¶Šä½“ç´ è¾¹ç•Œçš„ t å€¼

#### 3.2.3 è¯­ä¹‰æ ‡ç­¾åˆ†é…

**è§„åˆ™**ï¼š
- å¯¹æ¯ä¸ª voxelï¼š
  - å¦‚æœ `voxel_occ_count > 0`ï¼š
    - è¯¥ voxel ä¸º **occupied**
    - è¯­ä¹‰æ ‡ç­¾ = è¯¥ voxel å†…æ‰€æœ‰ç‚¹çš„ lidarseg æ ‡ç­¾çš„ **å¤šæ•°æŠ•ç¥¨**ï¼ˆmodeï¼‰
  - å¦åˆ™å¦‚æœ `voxel_free_count > 0`ï¼š
    - è¯¥ voxel ä¸º **free**ï¼ˆè¯­ä¹‰æ ‡ç­¾ = 17ï¼‰
  - å¦åˆ™ï¼š
    - è¯¥ voxel ä¸º **unobserved**ï¼ˆ`mask_lidar = 0`ï¼Œè¯­ä¹‰å¯ç½® 0 æˆ– 17ï¼Œä½†ä¼šè¢« mask å¿½ç•¥ï¼‰

#### 3.2.4 è¾“å‡º

- `semantics[X,Y,Z] uint8`: ä½“ç´ è¯­ä¹‰æ ‡ç­¾ï¼ˆ0~17ï¼Œå…¶ä¸­ 17 ä¸º freeï¼‰
- `mask_lidar[X,Y,Z] uint8`: **LiDAR Visibility Mask**ï¼ˆ0/1ï¼‰
  - å®šä¹‰ï¼š`mask_lidar = (voxel_free_count > 0) OR (voxel_occ_count > 0)`
  - å«ä¹‰ï¼š`mask_lidar==0` è¡¨ç¤ºè¯¥ voxel åœ¨ LiDAR view **unobserved**ï¼ˆé®æŒ¡æˆ–è¶…å‡ºè¦†ç›–ï¼‰
  - ä¸ Occ3D README å¯¹ `[mask_lidar]` çš„å®šä¹‰ä¸€è‡´ï¼Œè§ [Tsinghua-MARS-Lab/Occ3D](https://github.com/Tsinghua-MARS-Lab/Occ3D)

**å¤ç”¨ç°æœ‰ä»£ç **ï¼š
- `utils/custom.py:sparse2dense` - å¯ä½œä¸ºå‚è€ƒï¼Œä½†éœ€è¦æ‰©å±•ä¸ºæ”¯æŒ ray casting çš„ free space æ¨ç†

---

### 3.3 Stage 2: Occlusion Reasoning â€”â€” Camera Visibility Maskï¼ˆAlgorithm 3, CUDAï¼‰

#### 3.3.1 è¾“å…¥å‡†å¤‡

- `occupied_grid[X,Y,Z] uint8`: ä» `semantics` å’Œ `mask_lidar` å¾—åˆ°
  - `occupied_grid = (semantics != 17) & (mask_lidar == 1)`
- 6 ä¸ªç›¸æœºçš„å‚æ•°ï¼š
  - `K`: å†…å‚çŸ©é˜µ `(3, 3)`
  - `T_cam2ego`: å¤–å‚çŸ©é˜µ `(4, 4)`ï¼ˆç›¸æœºåˆ° ego çš„å˜æ¢ï¼‰
  - `img_w, img_h`: å›¾åƒåˆ†è¾¨ç‡ï¼ˆé»˜è®¤ä½¿ç”¨ nuScenes åŸå§‹åˆ†è¾¨ç‡ï¼‰

#### 3.3.2 å°„çº¿æ„é€ 

å¯¹æ¯ä¸ªåƒç´  `(u, v)`ï¼š
1. å°†åƒç´ åæ ‡è½¬æ¢ä¸ºç›¸æœºåæ ‡ç³»æ–¹å‘ï¼š
   - ä½¿ç”¨ `K^{-1}` è®¡ç®—å°„çº¿æ–¹å‘ï¼ˆå½’ä¸€åŒ–ï¼‰
2. å˜æ¢åˆ° ego åæ ‡ç³»ï¼š
   - `ray_origin_ego = T_cam2ego[:3, 3]`ï¼ˆç›¸æœºå…‰å¿ƒï¼‰
   - `ray_dir_ego = T_cam2ego[:3, :3] @ ray_dir_cam`

#### 3.3.3 CUDA Kernel è®¾è®¡

**Kernel ç­¾å**ï¼š
```cuda
__global__ void camera_ray_casting_kernel(
    const uint8_t* occupied_grid,      // [X*Y*Z]
    uint8_t* mask_camera_rays,          // [X*Y*Z], output
    const float* K_inv,                // [3*3], å†…å‚é€†çŸ©é˜µ
    const float* T_cam2ego,            // [4*4], å¤–å‚çŸ©é˜µ
    int img_w, int img_h,              // å›¾åƒåˆ†è¾¨ç‡
    const float* pc_range_min,        // [3], (x_min, y_min, z_min)
    const float* voxel_size,          // [3], (vx, vy, vz)
    const int* grid_size               // [3], (X, Y, Z)
)
```

**å¹¶è¡Œç­–ç•¥**ï¼š
- **Grid/Block é…ç½®**ï¼š
  - `blockDim = (16, 16)`ï¼ˆ256 çº¿ç¨‹/blockï¼‰
  - `gridDim = ((img_w + 15)/16, (img_h + 15)/16)`
  - æ¯ä¸ªçº¿ç¨‹å¤„ç†ä¸€ä¸ªåƒç´  `(u, v)`

**æ¯çº¿ç¨‹æµç¨‹**ï¼š
1. è®¡ç®—åƒç´ åæ ‡ï¼š`u = blockIdx.x * blockDim.x + threadIdx.x`, `v = blockIdx.y * blockDim.y + threadIdx.y`
2. æ£€æŸ¥è¾¹ç•Œï¼š`if (u >= img_w || v >= img_h) return;`
3. æ„é€ å°„çº¿ï¼š
   - `ray_dir_cam = K_inv @ [u, v, 1]^T`ï¼ˆå½’ä¸€åŒ–ï¼‰
   - `ray_origin_ego = T_cam2ego[:3, 3]`
   - `ray_dir_ego = T_cam2ego[:3, :3] @ ray_dir_cam`
4. Ray-Box ç›¸äº¤æµ‹è¯•ï¼ˆä¸ `pc_range` çš„ AABBï¼‰ï¼š
   - è®¡ç®— `t_enter` å’Œ `t_exit`
   - å¦‚æœ `t_enter >= t_exit`ï¼Œå°„çº¿ä¸ç©¿è¿‡ä½“ç´ ç½‘æ ¼ï¼Œç›´æ¥è¿”å›
5. 3D DDA éå†ï¼ˆä» `t_enter` å¼€å§‹ï¼‰ï¼š
   - å¯¹æ¯ä¸ªéå†åˆ°çš„ voxelï¼š
     - è®¡ç®— voxel ç´¢å¼• `idx = x + X*(y + Y*z)`
     - `atomicOr(&mask_camera_rays[idx], 1)`ï¼ˆæ ‡è®°ä¸º camera-observedï¼‰
     - å¦‚æœ `occupied_grid[idx] == 1`ï¼š**break**ï¼ˆé®æŒ¡ç»ˆæ­¢ï¼Œåæ–¹ä¸å†æ ‡è®°ï¼‰

#### 3.3.3 å¤šç›¸æœºèåˆ

å¯¹ 6 ä¸ªç›¸æœºåˆ†åˆ« launch kernelï¼Œç„¶åï¼š
- `mask_camera_rays = OR(mask_camera_rays_cam0, ..., mask_camera_rays_cam5)`

#### 3.3.4 æœ€ç»ˆ mask_camera

```
mask_camera = mask_lidar AND mask_camera_rays
```

**å®ç°**ï¼š

```python
mask_camera = np.logical_and(mask_lidar, mask_camera_rays).astype(np.uint8)
```

---

### 3.4 Stage 3: Image-guided Voxel Refinementï¼ˆå›¾åƒå¼•å¯¼ä½“ç´ ç»†åŒ–ï¼‰

å¯¹ç…§ `cursor_gen_files/Occ3D_Paper_Detailed_Interpretation.md`ï¼šStage 3 çš„ç›®æ ‡æ˜¯ä¿®å¤ 3D-2D misalignmentï¼ˆå§¿æ€æ¼‚ç§»/å™ªå£°é€ æˆçš„ 3D å¤–æ‰©ï¼‰ï¼Œé€šè¿‡ 2D è¯­ä¹‰æ²¿åƒç´ å°„çº¿â€œä¿®å‰ªâ€ 3D è¾¹ç•Œã€‚

#### 3.4.1 è¾“å…¥/è¾“å‡º

**è¾“å…¥**ï¼š
- Stage 2 è¾“å‡ºçš„ `semantics[X,Y,Z]`ã€`mask_lidar[X,Y,Z]`ã€ä»¥åŠç›¸æœºå‚æ•°ï¼ˆKã€T_cam2egoã€åŸå§‹åˆ†è¾¨ç‡ï¼‰
- æ¯ä¸ªç›¸æœºçš„ 2D è¯­ä¹‰ `seg2d_cam[h,w]`ï¼ˆæ¥æºå¯ä¸ºï¼š2D åˆ†å‰²æ¨¡å‹æ¨ç†ç»“æœï¼Œæˆ–ä½ ä»¬å·²æœ‰çš„ 2D æ ‡æ³¨/ä¼ªæ ‡æ³¨ï¼‰

**è¾“å‡º**ï¼š
- `semantics_refined[X,Y,Z]`ï¼šä¸»è¦å˜åŒ–æ˜¯å°†éƒ¨åˆ†â€œå‰æ™¯å¤–æ‰©â€çš„ occupied voxels ç½®ä¸º `free=17`

#### 3.4.2 æ ¸å¿ƒç®—æ³•ï¼ˆä¸è®ºæ–‡æè¿°å¯¹é½ï¼‰

å¯¹æ¯ä¸ªç›¸æœºã€æ¯ä¸ªåƒç´ ï¼ˆå»ºè®®åœ¨ ROI å†…ï¼‰ï¼š
1. è¯»å–åƒç´ è¯­ä¹‰ `c_2d = seg2d_cam[v,u]`
2. æ²¿åƒç´ å°„çº¿åœ¨ä½“ç´ ç½‘æ ¼å†…ä»è¿‘åˆ°è¿œ DDA éå† voxels
3. å½“é‡åˆ°**ç¬¬ä¸€ä¸ªè¯­ä¹‰ä¸ `c_2d` ä¸€è‡´**çš„ occupied voxel æ—¶ï¼š
   - å°†è¯¥ voxel ä¹‹å‰éå†è¿‡çš„ voxelsï¼ˆè‹¥è¢«æ ‡æˆ occupiedï¼‰å…¨éƒ¨ç½®ä¸º `free=17`

è¿™ä¸€æ­¥ä¼šæ˜¾è‘—æ”¹å–„ç‰©ä½“è¾¹ç•Œçš„ç²¾ç»†åº¦ï¼Œå¹¶æå‡ 3D-2D semantic consistencyã€‚

#### 3.4.3 ROI ä¸ç±»åˆ«æ˜ å°„

- **ROIï¼ˆæ¨èï¼‰**ï¼šæŒ‰è®ºæ–‡çš„ 2D ROI æ€è·¯ï¼ˆå•å¸§ LiDAR å¯æŠ•å½±è¦†ç›–çš„åŒºåŸŸï¼‰ï¼Œé¿å…åœ¨æ—  LiDAR è¦†ç›–åŒºåŸŸå¼•å…¥å™ªå£°ä¿®å‰ª
- **ç±»åˆ«æ˜ å°„**ï¼š2D åˆ†å‰²è¾“å‡ºç±»åˆ«éœ€æ˜ å°„åˆ° nuScenes-lidarseg çš„ 0~16 ä½“ç³»ï¼ˆä¸ `semantics` å¯¹é½ï¼‰ï¼Œ`free` ä¸æ¥è‡ª 2D

#### 3.4.4 ä¸ mask_camera çš„ä¸€è‡´æ€§ï¼ˆå»ºè®®ï¼‰

Stage 3 ä¼šæ”¹å˜ occupied çš„ç©ºé—´åˆ†å¸ƒï¼Œè¿›è€Œæ”¹å˜ â€œcamera ray çš„ç¬¬ä¸€ä¸ª occupied voxelâ€ ä½ç½®ã€‚ä¸ºäº†ä¸è®ºæ–‡å£å¾„æ›´ä¸€è‡´ï¼Œå»ºè®®ï¼š
- å…ˆ Stage 2 å¾—åˆ° `mask_camera_rays`
- Stage 3 å¾—åˆ° `semantics_refined`
- **å†åŸºäº `semantics_refined` é‡è·‘ä¸€æ¬¡ CUDA Algorithm 3** å¾—åˆ°æ–°çš„ `mask_camera_rays`
- æœ€ç»ˆï¼š`mask_camera = mask_lidar AND mask_camera_rays`

#### 3.4.5 å¼€å…³å»ºè®®

- `--enable-image-guided-refine`ï¼šæ˜¯å¦å¯ç”¨ Stage 3
- `--seg2d-mode {none,model,lidar_project,annotation}`ï¼š2D è¯­ä¹‰ç”Ÿæˆæ¨¡å¼ï¼ˆæ–°å¢æ¥å£ï¼šé€‰æ‹©æ–¹æ¡ˆA/æ–¹æ¡ˆB/éƒ½ä¸é€‰/ä½¿ç”¨å·²æœ‰æ ‡æ³¨ï¼‰
- `--seg2d-model / --seg2d-weights`ï¼š2D åˆ†å‰²æ¨¡å‹ä¸æƒé‡ï¼ˆè‹¥ seg2d-mode=modelï¼‰
- `--seg2d-cache-dir`ï¼š2D è¯­ä¹‰ç¼“å­˜ç›®å½•ï¼ˆä¿å­˜ `seg2d_cam`ï¼Œä¾›å¤ç”¨/æ–­ç‚¹ç»­è·‘ï¼‰
- `--refine-roi {lidar_roi, full_image}`ï¼šROI ç­–ç•¥

#### 3.4.6 å¦‚æœæœ¬é¡¹ç›®/æ•°æ®ä¾§æ²¡æœ‰æä¾› 2D è¯­ä¹‰ï¼ˆseg2d_camï¼‰ï¼Œæ€ä¹ˆåŠï¼Ÿ

è¿™æ˜¯ä¸€ä¸ªç°å®é—®é¢˜ï¼šOcc3D è®ºæ–‡çš„ Stage 3 ä¾èµ– `seg2d_cam[h,w]`ï¼Œä½† **nuScenes å®˜æ–¹æ•°æ®æœ¬èº«å¹¶ä¸ç›´æ¥æä¾›ä¸ Occ3D åŒå£å¾„çš„ 2D è¯­ä¹‰**ã€‚\n
å› æ­¤åœ¨å®æ–½æ—¶å¿…é¡»æä¾›ä¸€ä¸ªâ€œ2D è¯­ä¹‰ç”Ÿæˆæ¥å£â€ï¼Œç”¨äºé€‰æ‹©ï¼šæ–¹æ¡ˆ A / æ–¹æ¡ˆ B / éƒ½ä¸é€‰æ‹©ï¼ˆå…³é—­ Stage 3ï¼‰/ ä½¿ç”¨å·²æœ‰æ ‡æ³¨ï¼ˆè‹¥ä½ ä»¬æœªæ¥è¡¥é½ï¼‰ã€‚

ä¸ºé¿å… Stage 3 å®ç°ä¸ 2D è¯­ä¹‰æ¥æºå¼ºè€¦åˆï¼Œå»ºè®®æ–°å¢ç»Ÿä¸€æ¥å£ï¼š

```python
def build_or_load_seg2d_cam(
    sample_token: str,
    cam_name: str,
    nusc,
    seg2d_mode: str,  # 'none' | 'model' | 'lidar_project' | 'annotation'
    seg2d_cache_dir: str,
    *,
    model=None,
    class_mapper=None,
    lidar_points_ego=None,   # (N,3) in ego
    lidar_labels=None,       # (N,) 0..16
) -> "np.ndarray | None":
    \"\"\"è¿”å› seg2d_cam[h,w] (uint8, 0..16)ï¼Œè‹¥ seg2d_mode='none' åˆ™è¿”å› Noneã€‚\"\"\n
```

å¹¶åœ¨ Stage 3 ä¸»æµç¨‹ä¸­æ˜¾å¼åˆ†æ”¯ï¼š

```python
if not args.enable_image_guided_refine or args.seg2d_mode == 'none':
    # ä¸åš Stage 3ï¼ˆç­‰ä»·äºæ–¹æ¡ˆ Cï¼‰
    semantics_refined = semantics
else:
    # ä½¿ç”¨ seg2d_mode ç”Ÿæˆ/åŠ è½½ seg2d_camï¼Œç„¶ååš voxel refinement
    semantics_refined = image_guided_voxel_refine(...)
```

ä¸‹é¢ç»™å‡ºæ–¹æ¡ˆ A/B çš„â€œæ˜ç¡®ä»£ç å®ç°è¦ç‚¹ï¼ˆä¼ªä»£ç çº§åˆ«ï¼‰â€ï¼Œç¡®ä¿åç»­å¯ç›´æ¥è½åœ°ã€‚

##### 3.4.6-A æ–¹æ¡ˆ Aï¼š2D è¯­ä¹‰åˆ†å‰²æ¨¡å‹æ¨ç†ç”Ÿæˆ `seg2d_cam`ï¼ˆseg2d_mode='model'ï¼‰

**ç›®æ ‡**ï¼šå¯¹æ¯ä¸ªç›¸æœºå›¾åƒæ¨ç†å¾—åˆ° `seg2d_cam[h,w]`ï¼Œå¹¶æ˜ å°„åˆ° nuScenes-lidarseg çš„ 0..16 ç±»ã€‚\n
**è¾“å…¥**ï¼šç›¸æœºå›¾åƒè·¯å¾„ã€æ¨¡å‹æƒé‡ã€ç±»åˆ«æ˜ å°„è¡¨ã€‚\n
**è¾“å‡º**ï¼š`seg2d_cam[h,w] uint8`ï¼ˆç¼“å­˜åˆ° `seg2d_cache_dir`ï¼‰ã€‚

**å»ºè®®æ–°å¢æ¨¡å—**ï¼š`occ3d_nuscenes/seg2d_model.py`\n
**å»ºè®®å‡½æ•°ç­¾å**ï¼š

```python
def infer_seg2d_from_model(
    img_path: str,
    *,
    model,
    class_mapper,
    out_hw: tuple[int, int] | None = None,  # None=åŸå§‹åˆ†è¾¨ç‡ï¼›å¦åˆ™ resize å¹¶åŒæ­¥å¤„ç†
) -> "np.ndarray":
    \"\"\"è¿”å› seg2d_cam[h,w] uint8, å€¼åŸŸ 0..16ï¼ˆå¯¹é½ nuScenes-lidarsegï¼‰ã€‚\"\"\n
```

**ç¼“å­˜çº¦å®šï¼ˆå¼ºçƒˆå»ºè®®ï¼‰**ï¼š\n
- `seg2d_cache_dir/{split}/{scene_name}/{frame_token}/{CAM_NAME}.npy`\n
- dtype: `uint8`\n
- shape: `[h,w]`ï¼ˆä¸è¯¥ç›¸æœºåŸå§‹åˆ†è¾¨ç‡ä¸€è‡´ï¼Œæˆ–ä¸ `--camera-ray-image-size` ä¸€è‡´ï¼‰

**æ¨ç†ä¼ªä»£ç **ï¼š

```python
def build_or_load_seg2d_cam(..., seg2d_mode='model', model=None, class_mapper=None, ...):
    cache_path = make_cache_path(seg2d_cache_dir, split, scene_name, frame_token, cam_name)
    if os.path.exists(cache_path):
        return np.load(cache_path).astype(np.uint8)

    img_path = get_cam_img_path_from_nusc(sample_token, cam_name)
    seg_raw = model_infer(img_path, model=model)          # seg_raw: [h,w] in model label space
    seg2d = class_mapper.to_lidarseg(seg_raw)             # seg2d: [h,w] in 0..16
    np.save(cache_path, seg2d.astype(np.uint8))
    return seg2d
```

> è¯´æ˜ï¼šè¿™é‡Œ `class_mapper` çš„èŒè´£æ˜¯æŠŠ 2D æ¨¡å‹è¾“å‡ºç±»åˆ«æ˜ å°„åˆ° nuScenes-lidarseg çš„ 16 ç±»ï¼ˆ0..16ï¼Œ0 é€šå¸¸ä¸º ignore/voidï¼‰ã€‚ç±»åˆ«è¡¨å¯å‚è€ƒ `nuscenes-devkit lidarseg README`ï¼š`https://raw.githubusercontent.com/nutonomy/nuscenes-devkit/fcc41628d41060b3c1a86928751e5a571d2fc2fa/python-sdk/nuscenes/eval/lidarseg/README.md`ã€‚\n

##### 3.4.6-B æ–¹æ¡ˆ Bï¼šLiDAR è¯­ä¹‰æŠ•å½±åˆ°å›¾åƒç”Ÿæˆ `seg2d_cam`ï¼ˆseg2d_mode='lidar_project'ï¼‰

**ç›®æ ‡**ï¼šä¸ç”¨å¤–éƒ¨ 2D æ¨¡å‹ï¼Œä»…åˆ©ç”¨ LiDAR è¯­ä¹‰ç‚¹äº‘æŠ•å½±åˆ°æ¯ä¸ªç›¸æœºå¹³é¢å¾—åˆ° 2D ä¼ªæ ‡ç­¾ã€‚\n
**è¾“å…¥**ï¼š\n
- `lidar_points_ego (N,3)`ï¼ˆå»ºè®®ç”¨å½“å‰ keyframe çš„ LiDAR ç‚¹ï¼Œä¸ç”¨èšåˆç‚¹ï¼Œé¿å…æ—¶åºé”™ä½ï¼‰\n
- `lidar_labels (N,)`ï¼ˆ0..16ï¼‰\n
- ç›¸æœºå†…å‚ `K`ã€å¤–å‚ `T_cam2ego`ã€å›¾åƒå°ºå¯¸ `h,w`\n
**è¾“å‡º**ï¼š`seg2d_cam[h,w] uint8`ï¼ˆç¼“å­˜ï¼‰ã€‚

**å»ºè®®æ–°å¢æ¨¡å—**ï¼š`occ3d_nuscenes/seg2d_lidar_project.py`\n
**å»ºè®®å‡½æ•°ç­¾å**ï¼š

```python
def project_lidarseg_to_image(
    points_ego: "np.ndarray",   # (N,3)
    labels: "np.ndarray",       # (N,)
    K: "np.ndarray",            # (3,3)
    T_cam2ego: "np.ndarray",    # (4,4)
    img_hw: tuple[int, int],    # (h,w)
) -> "np.ndarray":
    \"\"\"è¿”å› seg2d_cam[h,w] uint8ï¼Œæœªè¦†ç›–åƒç´ å¡« 0ï¼ˆignore/voidï¼‰ã€‚\"\"\n
```

**å®ç°ä¼ªä»£ç ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰**ï¼š

```python
def project_lidarseg_to_image(points_ego, labels, K, T_cam2ego, img_hw):
    h, w = img_hw
    seg = np.zeros((h, w), dtype=np.uint8)
    depth = np.full((h, w), np.inf, dtype=np.float32)  # z-buffer: å–æœ€è¿‘ç‚¹

    T_ego2cam = np.linalg.inv(T_cam2ego)
    pts_cam = transform_points(points_ego, T_ego2cam)  # (N,3)

    # åªä¿ç•™ç›¸æœºå‰æ–¹
    mask = pts_cam[:, 2] > 1e-3
    pts_cam = pts_cam[mask]
    lbl = labels[mask].astype(np.uint8)

    # æŠ•å½±åˆ°åƒç´ 
    uvw = (K @ pts_cam.T).T  # (N,3)
    u = (uvw[:, 0] / uvw[:, 2]).astype(np.int32)
    v = (uvw[:, 1] / uvw[:, 2]).astype(np.int32)
    z = pts_cam[:, 2].astype(np.float32)

    in_img = (u >= 0) & (u < w) & (v >= 0) & (v < h)
    u, v, z, lbl = u[in_img], v[in_img], z[in_img], lbl[in_img]

    # z-buffer æ›´æ–°ï¼šåŒä¸€åƒç´ ä¿ç•™æœ€è¿‘ç‚¹è¯­ä¹‰
    for i in range(u.shape[0]):
        if z[i] < depth[v[i], u[i]]:
            depth[v[i], u[i]] = z[i]
            seg[v[i], u[i]] = lbl[i]

    # å¯é€‰ï¼šåšä¸€æ¬¡ç®€å•çš„å½¢æ€å­¦è†¨èƒ€/é—­è¿ç®—å¡«æ´ï¼ˆå¼±æ›¿ä»£ï¼‰
    # seg = postprocess(seg)
    return seg
```

**è¯´æ˜**ï¼š\n
- æ–¹æ¡ˆ B çš„ `seg2d_cam` ä¼šå¾ˆç¨€ç–ï¼Œå¿…é¡»ä¾èµ–åå¤„ç†ï¼ˆè†¨èƒ€/æ’å€¼ï¼‰æ‰èƒ½åœ¨ Stage 3 äº§ç”Ÿè¾ƒæ˜æ˜¾æ•ˆæœï¼›è¿™ä¹Ÿæ˜¯å®ƒå¼±äºè®ºæ–‡è®¾å®šçš„åŸå› ã€‚\n
- ä½†å®ƒçš„å¥½å¤„æ˜¯ï¼šä¸å¼•å…¥å¤–éƒ¨æ¨¡å‹ï¼Œèƒ½å°½å¿«è®© Stage 3 ä»£ç è·‘é€šå¹¶åšå¯¹é½å®éªŒã€‚

---

### 3.5 Exportï¼ˆéè®ºæ–‡ Stageï¼‰: æœ€ç»ˆè¾“å‡ºä¸å†™ç›˜

è¯´æ˜ï¼šè®ºæ–‡æµæ°´çº¿æ˜¯ 3 ä¸ªé˜¶æ®µï¼ˆStage 1/2/3ï¼‰ã€‚è¿™é‡Œçš„â€œå†™ç›˜ä¸å…ƒä¿¡æ¯å¯¼å‡ºâ€æ˜¯å·¥ç¨‹åŒ–çš„å¯¼å‡ºæ­¥éª¤ï¼Œä¸å±äºè®ºæ–‡å®šä¹‰çš„ä¸€ä¸ªæ–° stageï¼Œå› æ­¤ä¸å‘½åä¸º Stage 4ã€‚

#### 3.5.1 labels.npz æ ¼å¼

**æ–‡ä»¶è·¯å¾„**ï¼š`gts/[scene_name]/[frame_token]/labels.npz`

**å†…å®¹**ï¼ˆXYZ é¡ºåºï¼Œuint8ï¼‰ï¼š
```python
{
    'semantics': np.ndarray,      # [200, 200, 16] uint8, 0-17
    'mask_lidar': np.ndarray,     # [200, 200, 16] uint8, 0/1
    'mask_camera': np.ndarray,    # [200, 200, 16] uint8, 0/1
}
```

**å†™å…¥ä»£ç ç¤ºä¾‹**ï¼š
```python
np.savez_compressed(
    output_path,
    semantics=semantics.astype(np.uint8),
    mask_lidar=mask_lidar.astype(np.uint8),
    mask_camera=mask_camera.astype(np.uint8)
)
```

#### 3.5.2 annotations.json æ ¼å¼

**å®Œå…¨å¯¹é½å®˜æ–¹ README çš„ schema**ï¼š

```json
{
    "train_split": ["scene-0001", "scene-0002", ...],
    "val_split": ["scene-0003", "scene-0004", ...],
    "scene_infos": {
        "scene-0001": {
            "n015-2018-07-18-11-07-57+0800__CAM_BACK__1531883530437525": {
                "timestamp": "1531883530437525",
                "camera_sensor": {
                    "ca4d3d9de242603dae34ba357e07be62b": {
                        "img_path": "imgs/CAM_BACK/n015-2018-07-18-11-07-57+0800__CAM_BACK__1531883530437525.jpg",
                        "intrinsic": [[...], [...], [...]],
                        "extrinsic": {
                            "translation": [x, y, z],
                            "rotation": [w, x, y, z]
                        },
                        "ego_pose": {
                            "translation": [x, y, z],
                            "rotation": [w, x, y, z]
                        }
                    },
                    ...
                },
                "ego_pose": {
                    "translation": [x, y, z],
                    "rotation": [w, x, y, z]
                },
                "gt_path": "gts/scene-0001/n015-2018-07-18-11-07-57+0800__CAM_BACK__1531883530437525/labels.npz",
                "next": "next_frame_token",
                "prev": "prev_frame_token"
            },
            ...
        },
        ...
    }
}
```

#### 3.5.3 å›¾åƒæ–‡ä»¶å¤„ç†

**ç­–ç•¥**ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
1. **symlink**ï¼ˆæ¨èï¼ŒLinux æœåŠ¡å™¨ï¼‰ï¼š
   ```python
   os.symlink(src_path, dst_path)
   ```
2. **hardlink**ï¼ˆåŒç›˜æ›´çœç©ºé—´ï¼‰ï¼š
   ```python
   os.link(src_path, dst_path)
   ```
3. **copy**ï¼ˆæœ€æ…¢ï¼Œä½†æœ€é€šç”¨ï¼‰ï¼š
   ```python
   shutil.copy2(src_path, dst_path)
   ```

**è·¯å¾„æ˜ å°„**ï¼š
- æºï¼š`nuScenes/samples/CAM_*/xxx.jpg`
- ç›®æ ‡ï¼š`Occpancy3D-nuScenes-V1.0/trainval/imgs/CAM_*/xxx.jpg`

---

## 4. CUDA Algorithm 3 å®ç°ç»†èŠ‚

### 4.1 3D DDA ç®—æ³•ï¼ˆAlgorithm 1ï¼‰

**è¾“å…¥**ï¼š
- `ray_start`: å°„çº¿èµ·ç‚¹ `(x, y, z)`
- `ray_end`: å°„çº¿ç»ˆç‚¹ï¼ˆæˆ–æ–¹å‘ + æœ€å¤§æ·±åº¦ï¼‰
- `pc_range`: `[x_min, y_min, z_min, x_max, y_max, z_max]`
- `voxel_size`: `[vx, vy, vz]`
- `grid_size`: `[X, Y, Z]`

**ç®—æ³•æ­¥éª¤**ï¼ˆå‚è€ƒè®ºæ–‡è§£è¯»æ–‡æ¡£ï¼‰ï¼š
1. å°†å°„çº¿ç§»å…¥ç½‘æ ¼åæ ‡ç³»ï¼š`new_ray_start = ray_start - pc_range[0:3]`
2. è®¡ç®—æ¯ä¸ªè½´çš„ stepï¼ˆå‘å‰/å‘åèµ°ï¼‰
3. è®¡ç®— `tDelta`ï¼ˆè·¨è¿‡ä½“ç´ è¾¹é•¿æ‰€éœ€çš„å‚æ•° t å¢é‡ï¼‰
4. è®¡ç®— `cur_voxel` / `last_voxel`ï¼ˆèµ·æ­¢ä½“ç´ ï¼‰
5. è®¡ç®— `tMax`ï¼ˆä¸‹ä¸€æ¬¡åœ¨è½´ k ä¸Šè·¨è¶Šä½“ç´ è¾¹ç•Œçš„ t å€¼ï¼‰
6. ä½¿ç”¨ 3D DDA ç®—æ³•éå†ä½“ç´ 

**CUDA å®ç°ä¼ªä»£ç **ï¼š
```cuda
__device__ void ray_casting_3d_dda(
    float3 ray_start, float3 ray_dir, float t_max,
    float3 pc_range_min, float3 voxel_size, int3 grid_size,
    const uint8_t* occupied_grid, uint8_t* mask_camera_rays
) {
    // ç§»å…¥ç½‘æ ¼åæ ‡ç³»
    float3 start = make_float3(
        ray_start.x - pc_range_min.x,
        ray_start.y - pc_range_min.y,
        ray_start.z - pc_range_min.z
    );
    
    // è®¡ç®—ä½“ç´ ç´¢å¼•
    int3 cur_voxel = make_int3(
        (int)floorf(start.x / voxel_size.x),
        (int)floorf(start.y / voxel_size.y),
        (int)floorf(start.z / voxel_size.z)
    );
    
    // è®¡ç®— step å’Œ tDelta
    int3 step = make_int3(
        ray_dir.x > 0 ? 1 : -1,
        ray_dir.y > 0 ? 1 : -1,
        ray_dir.z > 0 ? 1 : -1
    );
    
    float3 tDelta = make_float3(
        abs(voxel_size.x / ray_dir.x),
        abs(voxel_size.y / ray_dir.y),
        abs(voxel_size.z / ray_dir.z)
    );
    
    // è®¡ç®— tMaxï¼ˆåˆ°ä¸‹ä¸€ä¸ªä½“ç´ è¾¹ç•Œçš„è·ç¦»ï¼‰
    float3 tMax = make_float3(
        ((cur_voxel.x + (step.x > 0 ? 1 : 0)) * voxel_size.x - start.x) / ray_dir.x,
        ((cur_voxel.y + (step.y > 0 ? 1 : 0)) * voxel_size.y - start.y) / ray_dir.y,
        ((cur_voxel.z + (step.z > 0 ? 1 : 0)) * voxel_size.z - start.z) / ray_dir.z
    );
    
    // DDA éå†
    while (t < t_max) {
        // æ£€æŸ¥è¾¹ç•Œ
        if (cur_voxel.x < 0 || cur_voxel.x >= grid_size.x ||
            cur_voxel.y < 0 || cur_voxel.y >= grid_size.y ||
            cur_voxel.z < 0 || cur_voxel.z >= grid_size.z) {
            break;
        }
        
        // è®¡ç®—çº¿æ€§ç´¢å¼•
        int idx = cur_voxel.x + grid_size.x * (cur_voxel.y + grid_size.y * cur_voxel.z);
        
        // æ ‡è®°ä¸º camera-observed
        atomicOr(&mask_camera_rays[idx], 1);
        
        // å¦‚æœé‡åˆ° occupied voxelï¼Œåœæ­¢ï¼ˆé®æŒ¡ï¼‰
        if (occupied_grid[idx] == 1) {
            break;
        }
        
        // é€‰æ‹©ä¸‹ä¸€ä¸ªè¦è·¨è¶Šçš„è½´
        if (tMax.x < tMax.y && tMax.x < tMax.z) {
            cur_voxel.x += step.x;
            tMax.x += tDelta.x;
        } else if (tMax.y < tMax.z) {
            cur_voxel.y += step.y;
            tMax.y += tDelta.y;
        } else {
            cur_voxel.z += step.z;
            tMax.z += tDelta.z;
        }
    }
}
```

### 4.2 å¤š GPU å¹¶è¡Œç­–ç•¥ï¼ˆå·²å®ç°ï¼‰

**å®ç°æ–¹å¼**ï¼šä½¿ç”¨ Python `multiprocessing.Pool` + GPU ç»‘å®š

**æ ¸å¿ƒæ¨¡å—**ï¼š
- `occ3d_nuscenes/camera_visibility_parallel.py`: å®ç° `process_sample_chunk_worker()` worker å‡½æ•°
- `generate_occ3d_nuscenes.py`: å®ç° `process_samples_parallel()` ä¸»è°ƒåº¦å‡½æ•°

**ä»»åŠ¡åˆ†é…ç­–ç•¥**ï¼š
1. æ”¶é›†æ‰€æœ‰ `(scene_name, sample_token)` å¯¹
2. æŒ‰ `--chunk-size` åˆ†å—ï¼ˆé»˜è®¤ 10 ä¸ª sample_token/chunkï¼‰
3. ä½¿ç”¨ `multiprocessing.Pool` å¯åŠ¨å¤šä¸ª workerï¼ˆworker æ•°é‡ = min(num_gpus, num_chunks)ï¼‰
4. æ¯ä¸ª worker ç»‘å®šåˆ°ä¸€ä¸ª GPUï¼ˆé€šè¿‡ `CUDA_VISIBLE_DEVICES`ï¼‰

**Worker å‡½æ•°**ï¼ˆ`process_sample_chunk_worker`ï¼‰ï¼š
```python
def process_sample_chunk_worker(
    worker_id: int,
    gpu_id: int,
    sample_tokens_chunk: List[Tuple[str, str]],  # [(scene_name, sample_token), ...]
    args_dict: Dict[str, Any],  # åºåˆ—åŒ–åçš„å‚æ•°
) -> Dict[str, Any]:
    # 1. ç»‘å®š GPU
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
    
    # 2. é‡å»ºå¤æ‚å¯¹è±¡ï¼ˆé¿å…è·¨è¿›ç¨‹å…±äº«ï¼‰
    grid = VoxelGridSpec()
    reader = NuScenesReader(...)
    
    # 3. å¤„ç†æ¯ä¸ª sample_tokenï¼ˆå®Œæ•´ pipelineï¼‰
    annotations = init_annotations()
    for scene_name, sample_token in sample_tokens_chunk:
        # Stage 1 â†’ Stage 2 â†’ Stage 3 â†’ Export
        ...
        update_annotations_for_frame(annotations, ...)
    
    # 4. è¿”å›ç»“æœ
    return {
        "annotations": annotations,
        "processed_count": ...,
        "errors": [...],
    }
```

**ä¸»è¿›ç¨‹è°ƒåº¦**ï¼ˆ`process_samples_parallel`ï¼‰ï¼š
```python
def process_samples_parallel(args, reader, grid):
    # 1. æ”¶é›†æ‰€æœ‰æ ·æœ¬
    all_samples = [(scene_name, sample_token) for ...]
    
    # 2. åˆ†å—
    chunks = [all_samples[i:i+chunk_size] for i in range(0, len(all_samples), chunk_size)]
    
    # 3. å¯åŠ¨ worker pool
    with multiprocessing.Pool(processes=num_workers) as pool:
        results = pool.starmap(process_sample_chunk_worker, worker_args)
    
    # 4. åˆå¹¶ annotations
    annotations = init_annotations()
    for result in results:
        merge_annotations(annotations, result["annotations"])
    
    # 5. å†™å…¥æœ€ç»ˆ annotations.json
    write_annotations_json(out_ann_path, annotations)
```

**å…³é”®ç‰¹æ€§**ï¼š
- âœ… GPU ç»‘å®šï¼šæ¯ä¸ª worker é€šè¿‡ `CUDA_VISIBLE_DEVICES` ç»‘å®šåˆ°æŒ‡å®š GPU
- âœ… å‚æ•°åºåˆ—åŒ–ï¼šåªä¼ é€’å¯åºåˆ—åŒ–çš„é…ç½®ï¼Œå¤æ‚å¯¹è±¡åœ¨ worker å†…éƒ¨é‡å»º
- âœ… é”™è¯¯å¤„ç†ï¼šæ¯ä¸ª worker æ•è·å¼‚å¸¸å¹¶è¿”å›é”™è¯¯åˆ—è¡¨
- âœ… è¿›åº¦è·Ÿè¸ªï¼šæ±‡æ€»æ‰€æœ‰ worker çš„å¤„ç†æ•°é‡
- âœ… æ–‡ä»¶å®‰å…¨ï¼šæ¯ä¸ª worker å†™å…¥ç‹¬ç«‹çš„ `labels.npz`ï¼Œä¸»è¿›ç¨‹ç»Ÿä¸€åˆå¹¶ `annotations.json`

---

## 5. æ–‡ä»¶ç»“æ„ä¸è¾“å‡ºæ ¼å¼

### 5.1 é¡¹ç›®ä»£ç ç»“æ„ï¼ˆå·²å®ç°ï¼‰

```
Occ3D-master/
â”œâ”€â”€ occ3d_nuscenes/              # Occ3D-nuScenes ç”Ÿæˆæ¨¡å—ï¼ˆå·²å®ç°ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ nusc_io.py               # nuScenes æ•°æ®è¯»å–ä¸åæ ‡å˜æ¢
â”‚   â”œâ”€â”€ accumulate.py            # Stage 1: å¤šå¸§èšåˆ
â”‚   â”œâ”€â”€ voxel_grid.py            # ä½“ç´ ç½‘æ ¼å®šä¹‰ä¸å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ lidar_visibility.py      # Stage 2: LiDAR ray casting (Algorithm 2)
â”‚   â”œâ”€â”€ camera_visibility.py     # Stage 2: Camera visibility (Algorithm 3, CPU/CUDA)
â”‚   â”œâ”€â”€ camera_visibility_parallel.py  # å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç† worker
â”‚   â”œâ”€â”€ cuda/                    # CUDA æ‰©å±•
â”‚   â”‚   â”œâ”€â”€ camera_visibility_ext.cpp
â”‚   â”‚   â””â”€â”€ camera_visibility_ext.cu
â”‚   â”œâ”€â”€ image_guided_refine.py   # Stage 3: Image-guided voxel refinement
â”‚   â”œâ”€â”€ seg2d_provider.py       # 2D è¯­ä¹‰ç»Ÿä¸€æ¥å£
â”‚   â”œâ”€â”€ seg2d_model.py          # æ–¹æ¡ˆA: 2D åˆ†å‰²æ¨¡å‹æ¨ç†
â”‚   â”œâ”€â”€ seg2d_lidar_project.py  # æ–¹æ¡ˆB: LiDAR æŠ•å½±ä¼ªæ ‡ç­¾
â”‚   â””â”€â”€ export_occ3d.py          # Export: è¾“å‡ºä¸å†™ç›˜ï¼ˆå« merge_annotationsï¼‰
â”œâ”€â”€ generate_occ3d_nuscenes.py  # ä¸»å…¥å£è„šæœ¬ï¼ˆæ ¹ç›®å½•ï¼‰
â”œâ”€â”€ utils/                       # ç°æœ‰ï¼šå¤ç”¨ç°æœ‰å·¥å…·
â”‚   â”œâ”€â”€ custom.py               # sparse2dense (å‚è€ƒ)
â”‚   â”œâ”€â”€ points_in_bbox.py       # åŠ¨æ€ç‰©ä½“å¯¹é½ï¼ˆå¤ç”¨ï¼‰
â”‚   â””â”€â”€ vis_occ.py              # å¯è§†åŒ–éªŒè¯ï¼ˆå¤ç”¨ï¼‰
â””â”€â”€ ...
```

### 5.2 è¾“å‡ºæ•°æ®é›†ç»“æ„ï¼ˆä¸¥æ ¼å¯¹é½å®˜æ–¹ï¼‰

```
Occpancy3D-nuScenes-V1.0/
â”œâ”€â”€ trainval/
â”‚   â”œâ”€â”€ imgs/
â”‚   â”‚   â”œâ”€â”€ CAM_BACK/
â”‚   â”‚   â”‚   â”œâ”€â”€ n015-2018-07-18-11-07-57+0800__CAM_BACK__1531883530437525.jpg
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ CAM_BACK_LEFT/
â”‚   â”‚   â”œâ”€â”€ CAM_BACK_RIGHT/
â”‚   â”‚   â”œâ”€â”€ CAM_FRONT/
â”‚   â”‚   â”œâ”€â”€ CAM_FRONT_LEFT/
â”‚   â”‚   â””â”€â”€ CAM_FRONT_RIGHT/
â”‚   â”œâ”€â”€ gts/
â”‚   â”‚   â”œâ”€â”€ scene-0001/
â”‚   â”‚   â”‚   â”œâ”€â”€ n015-2018-07-18-11-07-57+0800__CAM_BACK__1531883530437525/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ labels.npz
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ annotations.json
â””â”€â”€ test/
    â”œâ”€â”€ imgs/
    â””â”€â”€ annotations.json
```

### 5.3 labels.npz å­—æ®µè¯´æ˜

| å­—æ®µå | Shape | Dtype | è¯´æ˜ |
|--------|-------|-------|------|
| `semantics` | (200, 200, 16) | uint8 | ä½“ç´ è¯­ä¹‰æ ‡ç­¾ï¼Œ0-16 å¯¹åº” nuScenes-lidarsegï¼Œ17 ä¸º free |
| `mask_lidar` | (200, 200, 16) | uint8 | LiDAR å¯è§æ€§ maskï¼Œ0=unobservedï¼Œ1=observed |
| `mask_camera` | (200, 200, 16) | uint8 | ç›¸æœºå¯è§æ€§ maskï¼Œ0=unobservedï¼Œ1=observed |

**æ³¨æ„**ï¼š
- Shape ä¸º **XYZ é¡ºåº**ï¼š`(X=200, Y=200, Z=16)`
- ç´¢å¼• `(i, j, k)` å¯¹åº”çš„ç‰©ç†åæ ‡ï¼š
  - \(x = -40 + (i + 0.5) \times 0.4\)
  - \(y = -40 + (j + 0.5) \times 0.4\)
  - \(z = -1 + (k + 0.5) \times 0.4\)

---

## 6. é…ç½®å‚æ•°ä¸å‘½ä»¤è¡Œæ¥å£

### 6.1 å‘½ä»¤è¡Œå‚æ•°ï¼ˆå·²å®ç°ï¼‰

```python
# æ•°æ®è·¯å¾„
parser.add_argument('--nusc-root', type=str, default='/mnt/data/.../nuscenes/',
                    help='nuScenes æ•°æ®æ ¹ç›®å½•ï¼ˆæœåŠ¡å™¨ç«¯å®Œæ•´è·¯å¾„ï¼Œæœ‰é»˜è®¤å€¼ï¼‰')
parser.add_argument('--nusc-version', type=str, default='v1.0-trainval',
                    help='nuScenes ç‰ˆæœ¬')
parser.add_argument('--out-root', type=str, required=True,
                    help='è¾“å‡º Occ3D-nuScenes æ•°æ®é›†æ ¹ç›®å½•')
parser.add_argument('--split', type=str, choices=['trainval', 'test', 'mini'],
                    default='trainval', help='å¤„ç†çš„æ•°æ®é›† split')
parser.add_argument('--scene-name', type=str, default='',
                    help='å¦‚æœè®¾ç½®ï¼Œåªå¤„ç†æŒ‡å®šçš„åœºæ™¯')

# Stage 1 é€‰é¡¹
parser.add_argument('--window-size', type=int, default=21,
                    help='å¤šå¸§èšåˆçª—å£å¤§å°ï¼ˆé»˜è®¤ 21ï¼Œå½“å‰å¸§+å‰åå„10ï¼‰')
parser.add_argument('--enable-sweeps-densification', action='store_true',
                    help='æ˜¯å¦å¼•å…¥ sweeps å¹¶å¯¹ sweeps åš KNN è¯­ä¹‰èµ‹å€¼')
parser.add_argument('--enable-mesh-recon', action='store_true',
                    help='æ˜¯å¦å¯ç”¨ mesh/TSDF è¡¥æ´ï¼ˆStage 1 å¯é€‰æ­¥éª¤ï¼‰')
parser.add_argument('--mesh-recon-mode', type=str, choices=['tsdf', 'poisson'], default='tsdf',
                    help='mesh é‡å»ºæ¨¡å¼ï¼ˆtsdf æˆ– poissonï¼‰')

# Stage 2 é€‰é¡¹
parser.add_argument('--camera-mask-cuda', action='store_true',
                    help='ä½¿ç”¨ CUDA æ‰©å±•åŠ é€Ÿ Algorithm 3ï¼ˆå¦‚æœå¯ç”¨ï¼‰')

# å¹¶è¡Œå¤„ç†é€‰é¡¹
parser.add_argument('--num-gpus', type=int, default=1,
                    help='å¹¶è¡Œå¤„ç†ä½¿ç”¨çš„ GPU æ•°é‡')
parser.add_argument('--use-parallel-camera-visibility', action='store_true',
                    help='å¯ç”¨å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†ï¼ˆStage 2 Algorithm 3ï¼‰')
parser.add_argument('--chunk-size', type=int, default=10,
                    help='æ¯ä¸ª chunk çš„ sample_token æ•°é‡ï¼ˆå¹¶è¡Œå¤„ç†æ—¶ï¼‰')

# Stage 3 é€‰é¡¹
parser.add_argument('--enable-image-guided-refine', action='store_true',
                    help='æ˜¯å¦å¯ç”¨ Stage 3: Image-guided Voxel Refinement')
parser.add_argument('--seg2d-mode', type=str, 
                    choices=['none', 'model', 'lidar_project', 'annotation'], 
                    default='none',
                    help='2D è¯­ä¹‰ç”Ÿæˆæ¨¡å¼ï¼šnone=å…³é—­Stage3, model=æ–¹æ¡ˆA, lidar_project=æ–¹æ¡ˆB, annotation=å·²æœ‰æ ‡æ³¨')
parser.add_argument('--seg2d-cache-dir', type=str, default='',
                    help='2D è¯­ä¹‰ç¼“å­˜ç›®å½•ï¼ˆä¿å­˜/è¯»å– seg2d_camï¼‰')

# Export é€‰é¡¹
parser.add_argument('--link-method', type=str,
                    choices=['symlink', 'hardlink', 'copy'], default='symlink',
                    help='å›¾åƒæ–‡ä»¶é“¾æ¥æ–¹å¼ï¼ˆé»˜è®¤ symlinkï¼‰')
```

**æ³¨æ„**ï¼š
- `--num-train-scenes`, `--num-val-scenes`, `--seed` å·²åˆ é™¤ï¼ˆæœªä½¿ç”¨ï¼‰
- `--camera-ray-image-size`, `--seg2d-model`, `--seg2d-weights`, `--refine-roi`, `--gpus`, `--workers-per-gpu` æœªå®ç°ï¼ˆå½“å‰ç‰ˆæœ¬ï¼‰

### 6.2 ä½¿ç”¨ç¤ºä¾‹

**å•è¿›ç¨‹æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰**ï¼š
```bash
python generate_occ3d_nuscenes.py \
    --nusc-root /path/to/nuscenes \
    --out-root /path/to/Occpancy3D-nuScenes-V1.0 \
    --split trainval
```

**å¤šè¿›ç¨‹å¹¶è¡Œæ¨¡å¼**ï¼š
```bash
python generate_occ3d_nuscenes.py \
    --nusc-root /path/to/nuscenes \
    --out-root /path/to/Occpancy3D-nuScenes-V1.0 \
    --split trainval \
    --use-parallel-camera-visibility \
    --num-gpus 4 \
    --chunk-size 10 \
    --camera-mask-cuda
```

**å¯ç”¨ Stage 3ï¼ˆä½¿ç”¨ LiDAR æŠ•å½±æ–¹æ¡ˆBï¼‰**ï¼š
```bash
python generate_occ3d_nuscenes.py \
    --nusc-root /path/to/nuscenes \
    --out-root /path/to/Occpancy3D-nuScenes-V1.0 \
    --enable-image-guided-refine \
    --seg2d-mode lidar_project \
    --seg2d-cache-dir /path/to/cache
```

---

## 7. éªŒè¯ä¸æ£€æŸ¥ç‚¹

### 7.1 æ•°æ®å®Œæ•´æ€§æ£€æŸ¥

1. **æ–‡ä»¶æ•°é‡**ï¼š
   - æ£€æŸ¥ `gts/` ä¸‹æ¯ä¸ª scene çš„ frame æ•°é‡æ˜¯å¦ä¸ `annotations.json` ä¸€è‡´
   - æ£€æŸ¥ `imgs/` ä¸‹æ¯ä¸ªç›¸æœºçš„å›¾åƒæ•°é‡

2. **labels.npz æ ¼å¼**ï¼š
   ```python
   data = np.load('labels.npz')
   assert 'semantics' in data
   assert 'mask_lidar' in data
   assert 'mask_camera' in data
   assert data['semantics'].shape == (200, 200, 16)
   assert data['semantics'].dtype == np.uint8
   assert np.all(data['mask_camera'] <= data['mask_lidar'])  # mask_camera æ˜¯ mask_lidar çš„å­é›†
   ```

### 7.2 è¯­ä¹‰åˆç†æ€§æ£€æŸ¥

1. **free ç±»æ¯”ä¾‹**ï¼š
   - `semantics == 17` çš„æ¯”ä¾‹åº”è¯¥å¾ˆé«˜ï¼ˆé€šå¸¸ > 50%ï¼‰ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼ˆå¤§éƒ¨åˆ†ç©ºé—´æ˜¯ freeï¼‰

2. **mask å…³ç³»**ï¼š
   - `mask_camera` åº”è¯¥æ˜¯ `mask_lidar` çš„å­é›†ï¼ˆå› ä¸º AND æ“ä½œï¼‰
   - `mask_camera` çš„è¦†ç›–ç‡åº”è¯¥æ˜æ˜¾å°äº `mask_lidar`ï¼ˆç›¸æœºç›²åŒºå’Œé®æŒ¡å¯¼è‡´ï¼‰

3. **è¯­ä¹‰åˆ†å¸ƒ**ï¼š
   - æ£€æŸ¥ `semantics` çš„ç±»åˆ«åˆ†å¸ƒæ˜¯å¦åˆç†ï¼ˆ0-16 å¯¹åº” nuScenes-lidarseg ç±»åˆ«ï¼‰

### 7.3 å¯è§†åŒ–éªŒè¯ï¼ˆå¤ç”¨ç°æœ‰å·¥å…·ï¼‰

ä½¿ç”¨ `utils/vis_occ.py` å¯è§†åŒ–ç”Ÿæˆçš„ `labels.npz`ï¼š
```python
data = np.load('labels.npz')
semantics = data['semantics']
mask_lidar = data['mask_lidar']
mask_camera = data['mask_camera']

# ä½¿ç”¨ vis_occ.py çš„å¯è§†åŒ–å‡½æ•°
from utils.vis_occ import main as vis_occ
vis_occ(semantics, mask_lidar, mask_camera, voxel_size=[0.4, 0.4, 0.4])
```

**é¢„æœŸç»“æœ**ï¼š
- `mask_lidar` è¦†ç›–èŒƒå›´è¾ƒå¤§ï¼ˆåŒ…å« free spaceï¼‰
- `mask_camera` è¦†ç›–èŒƒå›´æ˜æ˜¾æ›´å°ï¼ˆè¢«é®æŒ¡å’Œç›²åŒºè£æ‰ï¼‰
- `semantics` ä¸­ freeï¼ˆ17ï¼‰å å¤§éƒ¨åˆ†ï¼Œoccupied ç±»åˆ«é›†ä¸­åœ¨ç‰©ä½“è¡¨é¢

### 7.4 ä¸å®˜æ–¹æ•°æ®å¯¹æ¯”ï¼ˆå¦‚æœæœ‰ï¼‰

å¦‚æœå¯ä»¥è·å¾—å®˜æ–¹ Occ3D-nuScenes çš„æ ·æœ¬æ•°æ®ï¼š
- å¯¹æ¯” `mask_lidar` å’Œ `mask_camera` çš„è¦†ç›–ç‡
- å¯¹æ¯”è¯­ä¹‰æ ‡ç­¾çš„åˆ†å¸ƒ
- å¯¹æ¯” `annotations.json` çš„ç»“æ„

---

## 8. ä¾èµ–ä¸ç¯å¢ƒè¦æ±‚

### 8.1 Python ä¾èµ–ï¼ˆéœ€è¦æ–°å¢ï¼‰

åœ¨ `requirement.txt` åŸºç¡€ä¸Šæ·»åŠ ï¼š
```
nuscenes-devkit>=1.1.0
pyquaternion>=0.9.0
```

### 8.2 CUDA è¦æ±‚

- **CUDA ç‰ˆæœ¬**ï¼š>= 10.2ï¼ˆæ”¯æŒ PyTorch CUDA extensionï¼‰
- **GPU æ˜¾å­˜**ï¼šå»ºè®®æ¯å¼  GPU >= 8GBï¼ˆå¤„ç† 200Ã—200Ã—16 çš„ä½“ç´ ç½‘æ ¼ï¼‰
- **PyTorch**ï¼šå·²åŒ…å«åœ¨ç°æœ‰ä¾èµ–ä¸­

### 8.3 CUDA Extensionï¼ˆå·²å®ç°ï¼‰

**å®ç°ä½ç½®**ï¼š
- `occ3d_nuscenes/cuda/camera_visibility_ext.cpp`: C++ ç»‘å®š
- `occ3d_nuscenes/cuda/camera_visibility_ext.cu`: CUDA kernel å®ç°

**ç¼–è¯‘æ–¹å¼**ï¼š
- ä½¿ç”¨ PyTorch çš„ JITï¼ˆJust-In-Timeï¼‰ç¼–è¯‘
- é¦–æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ç¼–è¯‘ï¼Œåç»­è¿è¡Œä¼šå¤ç”¨å·²ç¼–è¯‘çš„æ‰©å±•
- å¦‚æœç¼–è¯‘å¤±è´¥ï¼Œè‡ªåŠ¨å›é€€åˆ° CPU å‚è€ƒå®ç°

**ä½¿ç”¨æ–¹å¼**ï¼š
- é€šè¿‡ `--camera-mask-cuda` å‚æ•°å¯ç”¨ CUDA åŠ é€Ÿ
- `camera_visibility.py` ä¸­çš„ `_try_load_cuda_ext()` å‡½æ•°è´Ÿè´£åŠ è½½æ‰©å±•
- å¦‚æœ CUDA æ‰©å±•ä¸å¯ç”¨ï¼Œè‡ªåŠ¨ä½¿ç”¨ CPU å®ç°ï¼ˆ`camera_visibility_cpu()`ï¼‰

**æ³¨æ„**ï¼š
- JIT ç¼–è¯‘éœ€è¦ CUDA å·¥å…·é“¾ï¼ˆnvccï¼‰
- é¦–æ¬¡ç¼–è¯‘å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´
- ç¼–è¯‘åçš„æ‰©å±•ä¼šç¼“å­˜åœ¨ PyTorch çš„ç¼“å­˜ç›®å½•ä¸­

---

## 9. å®æ–½çŠ¶æ€

### âœ… Phase 1: åŸºç¡€æ¡†æ¶æ­å»ºï¼ˆå·²å®Œæˆï¼‰
- âœ… åˆ›å»º `occ3d_nuscenes/` ç›®å½•ç»“æ„
- âœ… å®ç° `nusc_io.py`ï¼ˆæ•°æ®è¯»å–ä¸åæ ‡å˜æ¢ï¼‰
- âœ… å®ç° `voxel_grid.py`ï¼ˆä½“ç´ ç½‘æ ¼å·¥å…·å‡½æ•°ï¼‰
- âœ… å®ç° `accumulate.py`ï¼ˆå¤šå¸§èšåˆï¼Œå¤ç”¨ `points_in_bbox.py`ï¼‰

### âœ… Phase 2: LiDAR Ray Castingï¼ˆå·²å®Œæˆï¼‰
- âœ… å®ç° `lidar_visibility.py`ï¼ˆCPU ç‰ˆæœ¬ï¼‰
- âœ… éªŒè¯ `semantics` å’Œ `mask_lidar` çš„ç”Ÿæˆ

### âœ… Phase 3: CUDA Algorithm 3ï¼ˆå·²å®Œæˆï¼‰
- âœ… ç¼–å†™ `cuda/camera_visibility_ext.cu`ï¼ˆCUDA kernelï¼‰
- âœ… ç¼–å†™ `cuda/camera_visibility_ext.cpp`ï¼ˆC++ ç»‘å®šï¼‰
- âœ… å®ç° `camera_visibility.py`ï¼ˆPython æ¥å£ï¼Œæ”¯æŒ CPU/CUDA è‡ªåŠ¨åˆ‡æ¢ï¼‰
- âœ… CUDA extension æ”¯æŒ JIT ç¼–è¯‘
- âœ… éªŒè¯ `mask_camera_rays` çš„ç”Ÿæˆ

### âœ… Phase 4: è¾“å‡ºä¸æ•´åˆï¼ˆå·²å®Œæˆï¼‰
- âœ… å®ç° `export_occ3d.py`ï¼ˆå†™ `labels.npz` å’Œ `annotations.json`ï¼‰
- âœ… å®ç° `merge_annotations()` å‡½æ•°ï¼ˆåˆå¹¶å¤šè¿›ç¨‹ç»“æœï¼‰
- âœ… å®ç°å›¾åƒæ–‡ä»¶å¤„ç†ï¼ˆsymlink/hardlink/copyï¼‰
- âœ… å®ç°å‘½ä»¤è¡Œå·¥å…· `generate_occ3d_nuscenes.py`ï¼ˆæ ¹ç›®å½•ï¼‰

### âœ… Phase 5: å¤š GPU å¹¶è¡Œä¸ä¼˜åŒ–ï¼ˆå·²å®Œæˆï¼‰
- âœ… å®ç° `camera_visibility_parallel.py`ï¼ˆå¤šè¿›ç¨‹ workerï¼‰
- âœ… å®ç° `process_samples_parallel()`ï¼ˆä¸»è°ƒåº¦å‡½æ•°ï¼‰
- âœ… ä½¿ç”¨ `multiprocessing.Pool` è¿›è¡Œä»»åŠ¡åˆ†é…
- âœ… GPU ç»‘å®šå’Œå‚æ•°åºåˆ—åŒ–

### âœ… Phase 6: Stage 3 å®ç°ï¼ˆå·²å®Œæˆï¼‰
- âœ… å®ç° `image_guided_refine.py`ï¼ˆCPU å‚è€ƒå®ç°ï¼‰
- âœ… å®ç° `seg2d_provider.py`ï¼ˆç»Ÿä¸€æ¥å£ï¼‰
- âœ… å®ç° `seg2d_model.py`ï¼ˆæ–¹æ¡ˆAï¼š2D æ¨¡å‹æ¨ç†ï¼Œå ä½ç¬¦ï¼‰
- âœ… å®ç° `seg2d_lidar_project.py`ï¼ˆæ–¹æ¡ˆBï¼šLiDAR æŠ•å½±ï¼‰

### ğŸ”„ Phase 7: éªŒè¯ä¸æ–‡æ¡£ï¼ˆè¿›è¡Œä¸­ï¼‰
- âœ… ä½¿ç”¨ `utils/vis_occ.py` å¯è§†åŒ–éªŒè¯ï¼ˆå¯ç”¨ï¼‰
- â³ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ï¼ˆå¾…å¤§è§„æ¨¡æµ‹è¯•ï¼‰
- â³ ä¸å®˜æ–¹æ ¼å¼å¯¹æ¯”ï¼ˆå¦‚æœæœ‰å®˜æ–¹æ•°æ®ï¼‰
- âœ… æ›´æ–°å®ç°è®¡åˆ’æ–‡æ¡£ï¼ˆæœ¬æ–‡æ¡£ï¼‰

---

## 10. å‚è€ƒæ–‡çŒ®ä¸é“¾æ¥

1. **è®ºæ–‡**ï¼š
   - [Occ3D: A Large-Scale 3D Occupancy Prediction Benchmark for Autonomous Driving](https://arxiv.org/pdf/2304.14365)

2. **å®˜æ–¹ä»“åº“**ï¼š
   - [Tsinghua-MARS-Lab/Occ3D](https://github.com/Tsinghua-MARS-Lab/Occ3D)

3. **nuScenes ç›¸å…³**ï¼š
   - [nuScenes-lidarseg README](https://raw.githubusercontent.com/nutonomy/nuscenes-devkit/fcc41628d41060b3c1a86928751e5a571d2fc2fa/python-sdk/nuscenes/eval/lidarseg/README.md)
   - [nuscenes-devkit](https://github.com/nutonomy/nuscenes-devkit)

4. **æœ¬åœ°æ–‡æ¡£**ï¼š
   - `cursor_gen_files/Occ3D_Paper_Detailed_Interpretation.md` - è®ºæ–‡è¯¦ç»†è§£è¯»

---

## é™„å½•ï¼šå…³é”®è®¾è®¡å†³ç­–æ€»ç»“

| å†³ç­–é¡¹ | é€‰æ‹© | ç†ç”± | çŠ¶æ€ |
|--------|------|------|------|
| å¤šå¸§èšåˆçª—å£ | 21 keyframesï¼ˆå½“å‰+å‰åå„10ï¼‰ | è®ºæ–‡æ˜ç¡®è¯´æ˜ï¼ŒnuScenes ä½¿ç”¨ 21 å¸§ | âœ… å·²å®ç° |
| åŠ¨æ€ç‰©ä½“ç±»åˆ« | vehicle/pedestrian/bicycle/motorcycle | movable_objectï¼ˆbarrier/coneï¼‰æŒ‰é™æ€å¤„ç†ï¼Œé¿å…å¯¹é½é”™è¯¯ | âœ… å·²å®ç° |
| mask_camera å®šä¹‰ | `mask_lidar & mask_camera_rays` | ç¡®ä¿åªåœ¨ LiDAR observed åŒºåŸŸè¯„æµ‹ï¼Œç¬¦åˆ vision-centric ä»»åŠ¡ | âœ… å·²å®ç° |
| ç›¸æœºåˆ†è¾¨ç‡ | é»˜è®¤ native | ä¸è®ºæ–‡ä¿æŒä¸€è‡´ï¼Œåƒç´ å°„çº¿ä¸å†…å‚ä¸¥æ ¼ç»‘å®š | âœ… å·²å®ç° |
| æ•°æ®æ ¼å¼ | XYZ é¡ºåºï¼Œuint8 dtype | ç»Ÿä¸€çº¦å®šï¼Œä¾¿äºåç»­è®­ç»ƒå’Œå¯è§†åŒ– | âœ… å·²å®ç° |
| å›¾åƒæ–‡ä»¶å¤„ç† | ä¼˜å…ˆ symlink | èŠ‚çœç©ºé—´ï¼Œé€‚åˆæœåŠ¡å™¨ç¯å¢ƒ | âœ… å·²å®ç° |
| å¤šGPUå¹¶è¡Œ | multiprocessing.Pool + GPUç»‘å®š | Python æ ‡å‡†åº“ï¼Œæ˜“äºå®ç°å’Œç»´æŠ¤ | âœ… å·²å®ç° |
| train/val split | æš‚ä¸å®ç° | å½“å‰ç‰ˆæœ¬å¤„ç†æ‰€æœ‰åœºæ™¯ï¼Œsplit ç”±ç”¨æˆ·é€šè¿‡ `--split` æŒ‡å®š | â³ å¾…å®ç° |
| Stage 3 seg2d | æ–¹æ¡ˆA/Bç»Ÿä¸€æ¥å£ | æ”¯æŒæ¨¡å‹æ¨ç†å’ŒLiDARæŠ•å½±ä¸¤ç§æ–¹å¼ | âœ… å·²å®ç° |

---

## 11. å·²çŸ¥é™åˆ¶ä¸æœªæ¥æ”¹è¿›

### 11.1 å½“å‰é™åˆ¶

1. **train/val split æœªå®ç°**ï¼š
   - å½“å‰ç‰ˆæœ¬å¤„ç†æ‰€æœ‰åœºæ™¯ï¼Œä¸è‡ªåŠ¨åˆ’åˆ† train/val
   - ç”¨æˆ·éœ€è¦æ‰‹åŠ¨æŒ‡å®š `--split` æˆ– `--scene-name`
   - æœªæ¥å¯æ·»åŠ åŸºäºåœºæ™¯åç§°çš„è‡ªåŠ¨åˆ’åˆ†é€»è¾‘

2. **Stage 3 æ–¹æ¡ˆAï¼ˆ2Dæ¨¡å‹æ¨ç†ï¼‰**ï¼š
   - `seg2d_model.py` ç›®å‰ä¸ºå ä½ç¬¦å®ç°
   - éœ€è¦é›†æˆå…·ä½“çš„ 2D åˆ†å‰²æ¨¡å‹ï¼ˆå¦‚ InternImageï¼‰
   - éœ€è¦å®ç°ç±»åˆ«æ˜ å°„è¡¨

3. **Mesh Reconstruction**ï¼š
   - `--enable-mesh-recon` å‚æ•°å·²å®šä¹‰ï¼Œä½†å®ç°å¯èƒ½ä¸å®Œæ•´
   - éœ€è¦éªŒè¯ TSDF/Poisson é‡å»ºçš„å®é™…æ•ˆæœ

4. **CUDA Extension ç¼–è¯‘**ï¼š
   - å½“å‰ä½¿ç”¨ JIT ç¼–è¯‘ï¼Œé¦–æ¬¡è¿è¡Œå¯èƒ½è¾ƒæ…¢
   - å»ºè®®é¢„ç¼–è¯‘æˆ–æä¾›é¢„ç¼–è¯‘ç‰ˆæœ¬

### 11.2 æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **I/O ä¼˜åŒ–**ï¼š
   - è€ƒè™‘ä½¿ç”¨å¼‚æ­¥ I/O æˆ–çº¿ç¨‹æ± å¤„ç†å›¾åƒé“¾æ¥
   - æ‰¹é‡å†™å…¥ `labels.npz` å‡å°‘æ–‡ä»¶ç³»ç»Ÿè°ƒç”¨

2. **å†…å­˜ä¼˜åŒ–**ï¼š
   - å¯¹äºå¤§è§„æ¨¡æ•°æ®é›†ï¼Œè€ƒè™‘æµå¼å¤„ç†
   - åŠæ—¶é‡Šæ”¾ä¸­é—´ç»“æœçš„å†…å­˜

3. **å¹¶è¡Œä¼˜åŒ–**ï¼š
   - å½“å‰ä½¿ç”¨è¿›ç¨‹çº§å¹¶è¡Œï¼Œå¯è€ƒè™‘çº¿ç¨‹çº§å¹¶è¡Œï¼ˆGIL é™åˆ¶ï¼‰
   - å¯¹äº I/O å¯†é›†å‹ä»»åŠ¡ï¼Œå¯å¢åŠ  worker æ•°é‡

---

**æ–‡æ¡£ç»“æŸ**

